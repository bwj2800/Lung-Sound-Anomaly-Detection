{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "\n",
    "mel_dir = '../data_4gr/mel_image'\n",
    "chroma_dir = '../data_4gr/chroma_image'\n",
    "mfcc_dir = '../data_4gr/mfcc_image'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC, Chroma, Mel-spectrogram from ICBHI Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Seed 설정\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "# 설정값\n",
    "sample_rate = 16000\n",
    "desired_length = 5\n",
    "n_mels = 64\n",
    "nfft = 2048\n",
    "hop = 512\n",
    "f_max = 4000\n",
    "\n",
    "# 파일 경로\n",
    "folds_file = '../ICBHI_Dataset/patient_list_foldwise.txt'\n",
    "data_dir = '../ICBHI_Dataset/audio_and_txt_files/'\n",
    "\n",
    "def Extract_Annotation_Data(file_name, data_dir):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data=[tokens], columns=['Patient Number', 'Recording index', 'Chest location', 'Acquisition mode', 'Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(data_dir, file_name + '.txt'), names=['Start', 'End', 'Crackles', 'Wheezes'], delimiter='\\t')\n",
    "    return recording_info, recording_annotations\n",
    "\n",
    "def get_annotations(data_dir):\n",
    "    filenames = [s.split('.')[0] for s in os.listdir(data_dir) if '.txt' in s]\n",
    "    i_list = []\n",
    "    rec_annotations_dict = {}\n",
    "    for s in filenames:\n",
    "        i, a = Extract_Annotation_Data(s, data_dir)\n",
    "        i_list.append(i)\n",
    "        rec_annotations_dict[s] = a\n",
    "    return filenames, rec_annotations_dict\n",
    "\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "    max_ind = len(raw_data)\n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind:end_ind]\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0:\n",
    "        return 0\n",
    "    elif crackle == 1 and wheeze == 0:\n",
    "        return 1\n",
    "    elif crackle == 0 and wheeze == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def get_sound_samples(recording_annotations, file_name, data_dir, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    data, rate = librosa.load(os.path.join(data_dir, file_name + '.wav'), sr=sample_rate)\n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start, end, get_label(crackles, wheezes)))\n",
    "    return sample_data\n",
    "\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "    S = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    S = (S - S.min()) / (S.max() - S.min())\n",
    "    S *= 255\n",
    "    S = cv2.applyColorMap(S.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    S = cv2.resize(S, (224, 224))  # Resize to a fixed size\n",
    "    return S\n",
    "\n",
    "def create_chroma(current_window, sample_rate):\n",
    "    chroma = librosa.feature.chroma_stft(y=current_window, sr=sample_rate)\n",
    "    chroma = (chroma - chroma.min()) / (chroma.max() - chroma.min())\n",
    "    chroma *= 255\n",
    "    chroma = cv2.applyColorMap(chroma.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    chroma = cv2.resize(chroma, (224, 224))  # Resize to a fixed size\n",
    "    return chroma\n",
    "\n",
    "def create_mfcc(current_window, sample_rate):\n",
    "    mfcc = librosa.feature.mfcc(y=current_window, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc = (mfcc - mfcc.min()) / (mfcc.max() - mfcc.min())\n",
    "    mfcc *= 255\n",
    "    mfcc = cv2.applyColorMap(mfcc.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    mfcc = cv2.resize(mfcc, (224, 224))  # Resize to a fixed size\n",
    "    return mfcc\n",
    "\n",
    "def save_image(array, save_path):\n",
    "    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Individual Cycles: 920it [00:10, 84.03it/s] \n"
     ]
    }
   ],
   "source": [
    "filenames, rec_annotations_dict = get_annotations(data_dir)\n",
    "\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [], []]\n",
    "for idx, file_name in tqdm(enumerate(filenames), desc=\"Extracting Individual Cycles\"):\n",
    "    data = get_sound_samples(rec_annotations_dict[file_name], file_name, data_dir, sample_rate)\n",
    "    cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, 0) for cycle_idx, d in enumerate(data[1:])]\n",
    "    cycle_list.extend(cycles_with_labels)\n",
    "    for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "        classwise_cycle_list[d[1]].append(d)\n",
    "\n",
    "# 데이터 증강\n",
    "scale = 1\n",
    "aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[0])\n",
    "for idx in range(aug_nos):\n",
    "    i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    normal_i = classwise_cycle_list[0][i]\n",
    "    normal_j = classwise_cycle_list[0][j]\n",
    "    new_sample = np.concatenate([normal_i[0], normal_j[0]])\n",
    "    cycle_list.append((new_sample, 0, normal_i[2] + '-' + normal_j[2], idx, 1))\n",
    "\n",
    "# 증강 함수 추가 (crackle, wheeze, both)\n",
    "def augment_class(class_index, classwise_cycle_list, scale):\n",
    "    aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[class_index])\n",
    "    for idx in range(aug_nos):\n",
    "        aug_prob = random.random()\n",
    "        if aug_prob < 0.6:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        elif aug_prob >= 0.6 and aug_prob < 0.8:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[0][j]\n",
    "        else:\n",
    "            i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[0][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        new_sample = np.concatenate([sample_i[0], sample_j[0]])\n",
    "        cycle_list.append((new_sample, class_index, sample_i[2] + '-' + sample_j[2], idx, 1))\n",
    "\n",
    "augment_class(1, classwise_cycle_list, scale)\n",
    "augment_class(2, classwise_cycle_list, scale)\n",
    "augment_class(3, classwise_cycle_list, scale)\n",
    "\n",
    "# 오디오 데이터 정렬\n",
    "desiredLength = 8\n",
    "output = []\n",
    "for idx, sample in enumerate(cycle_list):\n",
    "    output_buffer_length = int(desiredLength * sample_rate)\n",
    "    soundclip = sample[0].copy()\n",
    "    n_samples = len(soundclip)\n",
    "    if n_samples < output_buffer_length:\n",
    "        t = output_buffer_length // n_samples\n",
    "        d = output_buffer_length % n_samples\n",
    "        d = soundclip[:d]\n",
    "        repeat_sample = np.concatenate((np.tile(soundclip, t), d))\n",
    "        copy_repeat_sample = repeat_sample.copy()\n",
    "        output.append((copy_repeat_sample, sample[1]))\n",
    "    else:\n",
    "        copy_repeat_sample = soundclip[:output_buffer_length]\n",
    "        output.append((copy_repeat_sample, sample[1]))\n",
    "audio_data = output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images:   0%|          | 0/14568 [00:00<?, ?it/s]c:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Saving Images:   0%|          | 3/14568 [00:00<19:05, 12.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images: 100%|██████████| 14568/14568 [18:02<00:00, 13.46it/s]\n",
      "Saving Images in dir: 100%|██████████| 14568/14568 [02:31<00:00, 95.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mel-spectrogram, chroma, MFCC 이미지 생성 및 저장\n",
    "mel_img = []\n",
    "chroma_img = []\n",
    "mfcc_img = []\n",
    "for index in tqdm(range(len(audio_data)), desc=\"Saving Images\"):\n",
    "    audio = audio_data[index][0]\n",
    "    label = audio_data[index][1]\n",
    "    mel_image = create_mel_raw(audio, sample_rate, f_max=f_max, n_mels=n_mels, nfft=nfft, hop=hop, resz=1)\n",
    "    chroma_image = create_chroma(audio, sample_rate)\n",
    "    mfcc_image = create_mfcc(audio, sample_rate)\n",
    "    mel_img.append((mel_image, label))\n",
    "    chroma_img.append((chroma_image, label))\n",
    "    mfcc_img.append((mfcc_image, label))\n",
    "\n",
    "destination_dir = '../data_4gr'\n",
    "mel_dir = os.path.join(destination_dir, 'mel_image')\n",
    "chroma_dir = os.path.join(destination_dir, 'chroma_image')\n",
    "mfcc_dir = os.path.join(destination_dir, 'mfcc_image')\n",
    "\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "os.makedirs(chroma_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_dir, exist_ok=True)\n",
    "\n",
    "# Create the four folders for the labels in each image type directory\n",
    "for label in ['normal', 'crackle', 'wheeze', 'both']:\n",
    "    os.makedirs(os.path.join(mel_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(chroma_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(mfcc_dir, label), exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(len(mel_img)), desc=\"Saving Images in dir\"):\n",
    "    input_mel = mel_img[i][0]\n",
    "    input_chroma = chroma_img[i][0]\n",
    "    input_mfcc = mfcc_img[i][0]\n",
    "    label = mel_img[i][1]\n",
    "    \n",
    "    if label == 0:\n",
    "        mel_save_path = os.path.join(mel_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 1:\n",
    "        mel_save_path = os.path.join(mel_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 2:\n",
    "        mel_save_path = os.path.join(mel_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "    else:\n",
    "        mel_save_path = os.path.join(mel_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "    \n",
    "    cv2.imwrite(mel_save_path, cv2.cvtColor(input_mel, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(chroma_save_path, cv2.cvtColor(input_chroma, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(mfcc_save_path, cv2.cvtColor(input_mfcc, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICBHI image 분산, 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.7520, 0.4380, 0.1649]), Std: tensor([0.2788, 0.3732, 0.2812])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mel_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Mel-spectrogram Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma Mean: tensor([0.2995, 0.4973, 0.6374]), Std: tensor([0.3043, 0.3505, 0.2868])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/chroma_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Chroma Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC Mean: tensor([0.0714, 0.4974, 0.8972]), Std: tensor([0.1645, 0.2059, 0.2028])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mfcc_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'MFCC Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel-spectrogram old Mean: tensor([0.3416, 0.1199, 0.3481]), Std: tensor([0.2769, 0.1272, 0.1512])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mel_image_old', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Mel-spectrogram old Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDLINet\n",
    "- remove baseline wandering\n",
    "- pitch shifting\n",
    "- add noise\n",
    "- normalize signal\n",
    "- sample rate 4000\n",
    "- nfft 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khsfu\\AppData\\Local\\Temp\\ipykernel_6084\\2023677017.py:16: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import cmapy\n",
    "\n",
    "# Seed 설정\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "# 설정값\n",
    "sample_rate = 4000#16000\n",
    "desired_length = 5\n",
    "n_mels = 64\n",
    "nfft = 1024#2048\n",
    "hop = 512\n",
    "f_max = 4000\n",
    "\n",
    "# 파일 경로\n",
    "folds_file = '../ICBHI_Dataset/patient_list_foldwise.txt'\n",
    "data_dir = '../ICBHI_Dataset/audio_and_txt_files/'\n",
    "mel_dir = '../data_4gr/mel_image_rdlinet'\n",
    "chroma_dir = '../data_4gr/chroma_image_rdlinet'\n",
    "mfcc_dir = '../data_4gr/mfcc_image_rdlinet'\n",
    "\n",
    "def Extract_Annotation_Data(file_name, data_dir):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data=[tokens], columns=['Patient Number', 'Recording index', 'Chest location', 'Acquisition mode', 'Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(data_dir, file_name + '.txt'), names=['Start', 'End', 'Crackles', 'Wheezes'], delimiter='\\t')\n",
    "    return recording_info, recording_annotations\n",
    "\n",
    "def get_annotations(data_dir):\n",
    "    filenames = [s.split('.')[0] for s in os.listdir(data_dir) if '.txt' in s]\n",
    "    i_list = []\n",
    "    rec_annotations_dict = {}\n",
    "    for s in filenames:\n",
    "        i, a = Extract_Annotation_Data(s, data_dir)\n",
    "        i_list.append(i)\n",
    "        rec_annotations_dict[s] = a\n",
    "    return filenames, rec_annotations_dict\n",
    "\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "    max_ind = len(raw_data)\n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind:end_ind]\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0:\n",
    "        return 0\n",
    "    elif crackle == 1 and wheeze == 0:\n",
    "        return 1\n",
    "    elif crackle == 0 and wheeze == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def get_sound_samples(recording_annotations, file_name, data_dir, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    data, rate = librosa.load(os.path.join(data_dir, file_name + '.wav'), sr=sample_rate)\n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start, end, get_label(crackles, wheezes)))\n",
    "    return sample_data\n",
    "\n",
    "def remove_baseline_wandering(signal, sample_rate):\n",
    "    n = len(signal)\n",
    "    freq = np.fft.fftfreq(n, d=1/sample_rate)\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    fft_signal[np.abs(freq) < 1] = 0  # Remove frequencies below 1 Hz\n",
    "    filtered_signal = np.fft.ifft(fft_signal)\n",
    "    return np.real(filtered_signal)\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    return signal / np.max(np.abs(signal))\n",
    "\n",
    "def pitch_shift(signal, sr, n_steps):\n",
    "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def add_noise(signal, snr):\n",
    "    noise = np.random.normal(0, 1, signal.shape)\n",
    "    signal_power = np.mean(signal**2)\n",
    "    noise_power = signal_power / (10**(snr / 10))\n",
    "    noise = noise * np.sqrt(noise_power)\n",
    "    return signal + noise\n",
    "\n",
    "\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "    S = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    S = (S - S.min()) / (S.max() - S.min())\n",
    "    S *= 255\n",
    "    S = cv2.applyColorMap(S.astype(np.uint8), cmapy.cmap('plasma'))\n",
    "    S = cv2.resize(S, (224, 224))  # Resize to a fixed size\n",
    "    S = cv2.flip(S, 0)\n",
    "    return S\n",
    "\n",
    "def create_chroma(current_window, sample_rate):\n",
    "    chroma = librosa.feature.chroma_stft(y=current_window, sr=sample_rate)\n",
    "    chroma = (chroma - chroma.min()) / (chroma.max() - chroma.min())\n",
    "    chroma *= 255\n",
    "    chroma = cv2.applyColorMap(chroma.astype(np.uint8), cmapy.cmap('inferno'))\n",
    "    chroma = cv2.resize(chroma, (224, 224))  # Resize to a fixed size\n",
    "    chroma = cv2.flip(chroma, 0)\n",
    "    return chroma\n",
    "\n",
    "def create_mfcc(current_window, sample_rate):\n",
    "    mfcc = librosa.feature.mfcc(y=current_window, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc = (mfcc - mfcc.min()) / (mfcc.max() - mfcc.min())\n",
    "    mfcc *= 255\n",
    "    mfcc = cv2.applyColorMap(mfcc.astype(np.uint8), cmapy.cmap('viridis'))\n",
    "    mfcc = cv2.resize(mfcc, (224, 224))  # Resize to a fixed size\n",
    "    mfcc = cv2.flip(mfcc, 0)\n",
    "    return mfcc\n",
    "\n",
    "def save_image(array, save_path):\n",
    "    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Individual Cycles: 920it [00:11, 81.04it/s] \n"
     ]
    }
   ],
   "source": [
    "filenames, rec_annotations_dict = get_annotations(data_dir)\n",
    "\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [], []]\n",
    "for idx, file_name in tqdm(enumerate(filenames), desc=\"Extracting Individual Cycles\"):\n",
    "    data = get_sound_samples(rec_annotations_dict[file_name], file_name, data_dir, sample_rate)\n",
    "    cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, 0) for cycle_idx, d in enumerate(data[1:])]\n",
    "    cycle_list.extend(cycles_with_labels)\n",
    "    for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "        classwise_cycle_list[d[1]].append(d)\n",
    "\n",
    "# 데이터 증강\n",
    "scale = 1\n",
    "aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[0])\n",
    "for idx in range(aug_nos):\n",
    "    i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    normal_i = classwise_cycle_list[0][i]\n",
    "    normal_j = classwise_cycle_list[0][j]\n",
    "    new_sample = np.concatenate([normal_i[0], normal_j[0]])\n",
    "    cycle_list.append((new_sample, 0, normal_i[2] + '-' + normal_j[2], idx, 1))\n",
    "\n",
    "# 증강 함수 추가 (crackle, wheeze, both)\n",
    "def augment_class(class_index, classwise_cycle_list, scale):\n",
    "    aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[class_index])\n",
    "    for idx in range(aug_nos):\n",
    "        aug_prob = random.random()\n",
    "        if aug_prob < 0.6:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        elif aug_prob >= 0.6 and aug_prob < 0.8:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[0][j]\n",
    "        else:\n",
    "            i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[0][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        new_sample = np.concatenate([sample_i[0], sample_j[0]])\n",
    "        cycle_list.append((new_sample, class_index, sample_i[2] + '-' + sample_j[2], idx, 1))\n",
    "\n",
    "augment_class(1, classwise_cycle_list, scale)\n",
    "augment_class(2, classwise_cycle_list, scale)\n",
    "augment_class(3, classwise_cycle_list, scale)\n",
    "\n",
    "# 오디오 데이터 정렬\n",
    "desiredLength = 8\n",
    "output = []\n",
    "for idx, sample in enumerate(cycle_list):\n",
    "    output_buffer_length = int(desiredLength * sample_rate)\n",
    "    soundclip = sample[0].copy()\n",
    "    n_samples = len(soundclip)\n",
    "    if n_samples < output_buffer_length:\n",
    "        t = output_buffer_length // n_samples\n",
    "        d = output_buffer_length % n_samples\n",
    "        d = soundclip[:d]\n",
    "        repeat_sample = np.concatenate((np.tile(soundclip, t), d))\n",
    "        copy_repeat_sample = repeat_sample.copy()\n",
    "        # output.append((copy_repeat_sample, sample[1]))\n",
    "    else:\n",
    "        copy_repeat_sample = soundclip[:output_buffer_length]\n",
    "        # output.append((copy_repeat_sample, sample[1]))\n",
    "    # print('before sample type: ', type(copy_repeat_sample))\n",
    "    # Baseline Wandering removal\n",
    "    # 전처리: 베이스라인 방황 제거 및 정규화\n",
    "    copy_repeat_sample = remove_baseline_wandering(copy_repeat_sample, sample_rate)\n",
    "    copy_repeat_sample = normalize_signal(copy_repeat_sample)\n",
    "    \n",
    "    # 원본 신호 추가\n",
    "    output.append((copy_repeat_sample, sample[1]))\n",
    "\n",
    "    # 증강: 피치 변환 및 노이즈 추가\n",
    "    augmented_sample = pitch_shift(copy_repeat_sample, sample_rate, -2)\n",
    "    output.append((augmented_sample, sample[1]))\n",
    "    # for n_steps in [-2, 1]:\n",
    "    #     augmented_sample = pitch_shift(copy_repeat_sample, sample_rate, n_steps)\n",
    "    #     output.append((augmented_sample, sample[1]))\n",
    "\n",
    "    augmented_sample = add_noise(copy_repeat_sample, 10)\n",
    "    output.append((augmented_sample, sample[1]))\n",
    "\n",
    "audio_data = output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images:   0%|          | 0/43704 [00:00<?, ?it/s]c:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\feature\\spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "c:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Saving Images: 100%|██████████| 43704/43704 [1:25:43<00:00,  8.50it/s]\n",
      "Saving Images in dir: 100%|██████████| 43704/43704 [13:59<00:00, 52.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mel-spectrogram, chroma, MFCC 이미지 생성 및 저장\n",
    "mel_img = []\n",
    "chroma_img = []\n",
    "mfcc_img = []\n",
    "for index in tqdm(range(len(audio_data)), desc=\"Saving Images\"):\n",
    "    audio = audio_data[index][0]\n",
    "    label = audio_data[index][1]\n",
    "    mel_image = create_mel_raw(audio, sample_rate, f_max=f_max, n_mels=n_mels, nfft=nfft, hop=hop, resz=1)\n",
    "    chroma_image = create_chroma(audio, sample_rate)\n",
    "    mfcc_image = create_mfcc(audio, sample_rate)\n",
    "    mel_img.append((mel_image, label))\n",
    "    chroma_img.append((chroma_image, label))\n",
    "    mfcc_img.append((mfcc_image, label))\n",
    "\n",
    "# destination_dir = '../data_4gr'\n",
    "# mel_dir = os.path.join(destination_dir, 'mel_image')\n",
    "# chroma_dir = os.path.join(destination_dir, 'chroma_image')\n",
    "# mfcc_dir = os.path.join(destination_dir, 'mfcc_image')\n",
    "\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "os.makedirs(chroma_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_dir, exist_ok=True)\n",
    "\n",
    "# Create the four folders for the labels in each image type directory\n",
    "for label in ['normal', 'crackle', 'wheeze', 'both']:\n",
    "    os.makedirs(os.path.join(mel_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(chroma_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(mfcc_dir, label), exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(len(mel_img)), desc=\"Saving Images in dir\"):\n",
    "    input_mel = mel_img[i][0]\n",
    "    input_chroma = chroma_img[i][0]\n",
    "    input_mfcc = mfcc_img[i][0]\n",
    "    label = mel_img[i][1]\n",
    "    \n",
    "    if label == 0:\n",
    "        mel_save_path = os.path.join(mel_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 1:\n",
    "        mel_save_path = os.path.join(mel_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 2:\n",
    "        mel_save_path = os.path.join(mel_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "    else:\n",
    "        mel_save_path = os.path.join(mel_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "    \n",
    "    cv2.imwrite(mel_save_path, cv2.cvtColor(input_mel, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(chroma_save_path, cv2.cvtColor(input_chroma, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(mfcc_save_path, cv2.cvtColor(input_mfcc, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
