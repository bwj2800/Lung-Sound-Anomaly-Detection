{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "\n",
    "mel_dir = '../data_4gr/mel_image'\n",
    "chroma_dir = '../data_4gr/chroma_image'\n",
    "mfcc_dir = '../data_4gr/mfcc_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing both:   0%|          | 0/3642 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing both:  21%|██        | 763/3642 [50:54<3:12:05,  4.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m mel_spectrogram \u001b[38;5;241m=\u001b[39m process_image(mel_path)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Convert mel-spectrogram to audio signal\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmel_to_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_spectrogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Compute chroma\u001b[39;00m\n\u001b[0;32m     40\u001b[0m chroma \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mchroma_stft(y\u001b[38;5;241m=\u001b[39my, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m, n_chroma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\feature\\inverse.py:192\u001b[0m, in \u001b[0;36mmel_to_audio\u001b[1;34m(M, sr, n_fft, hop_length, win_length, window, center, pad_mode, power, n_iter, length, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invert a mel power spectrogram to audio using Griffin-Lim.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03mThis is primarily a convenience wrapper for:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03mlibrosa.feature.inverse.mel_to_stft\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m stft \u001b[38;5;241m=\u001b[39m mel_to_stft(M, sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, power\u001b[38;5;241m=\u001b[39mpower, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgriffinlim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\spectrum.py:2724\u001b[0m, in \u001b[0;36mgriffinlim\u001b[1;34m(S, n_iter, hop_length, win_length, n_fft, window, center, dtype, length, pad_mode, momentum, init, random_state)\u001b[0m\n\u001b[0;32m   2722\u001b[0m     angles \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m S\n\u001b[0;32m   2723\u001b[0m     \u001b[38;5;66;03m# Store\u001b[39;00m\n\u001b[1;32m-> 2724\u001b[0m     rebuilt, tprev \u001b[38;5;241m=\u001b[39m tprev, rebuilt\n\u001b[0;32m   2726\u001b[0m \u001b[38;5;66;03m# Return the final phase estimates\u001b[39;00m\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m istft(\n\u001b[0;32m   2728\u001b[0m     angles,\n\u001b[0;32m   2729\u001b[0m     hop_length\u001b[38;5;241m=\u001b[39mhop_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2736\u001b[0m     out\u001b[38;5;241m=\u001b[39minverse,\n\u001b[0;32m   2737\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def save_image(array, save_path):\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     librosa.display.specshow(array, sr=16000, x_axis='time')\n",
    "#     plt.colorbar(format='%+2.0f dB')\n",
    "#     plt.savefig(save_path)\n",
    "#     plt.close()\n",
    "def save_image(array, save_path):\n",
    "    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(save_path)\n",
    "\n",
    "def process_image(image_path):\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "for class_name in ['both', 'wheeze', 'crackle', 'normal']:\n",
    "    mel_class_dir = os.path.join(mel_dir, class_name)\n",
    "    chroma_class_dir = os.path.join(chroma_dir, class_name)\n",
    "    mfcc_class_dir = os.path.join(mfcc_dir, class_name)\n",
    "    \n",
    "    if not os.path.exists(chroma_class_dir):\n",
    "        os.makedirs(chroma_class_dir)\n",
    "    if not os.path.exists(mfcc_class_dir):\n",
    "        os.makedirs(mfcc_class_dir)\n",
    "    \n",
    "    file_names = os.listdir(mel_class_dir)\n",
    "    \n",
    "    for file_name in tqdm(file_names, desc=f\"Processing {class_name}\"):\n",
    "        mel_path = os.path.join(mel_class_dir, file_name)\n",
    "        \n",
    "        # Process mel-spectrogram image\n",
    "        mel_spectrogram = process_image(mel_path)\n",
    "        \n",
    "        # Convert mel-spectrogram to audio signal\n",
    "        y = librosa.feature.inverse.mel_to_audio(mel_spectrogram, sr=16000)\n",
    "        \n",
    "        # Compute chroma\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=16000, n_chroma=12)\n",
    "        chroma_save_path = os.path.join(chroma_class_dir, file_name)\n",
    "        save_image(chroma, chroma_save_path)\n",
    "        \n",
    "        # Compute MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=16000, n_mfcc=13)\n",
    "        mfcc_save_path = os.path.join(mfcc_class_dir, file_name)\n",
    "        save_image(mfcc, mfcc_save_path)\n",
    "\n",
    "print(\"Chroma and MFCC images generated successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC, Chroma, Mel-spectrogram from ICBHI Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Seed 설정\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "# 설정값\n",
    "sample_rate = 16000\n",
    "desired_length = 5\n",
    "n_mels = 64\n",
    "nfft = 2048\n",
    "hop = 512\n",
    "f_max = 4000\n",
    "\n",
    "# 파일 경로\n",
    "folds_file = '../ICBHI_Dataset/patient_list_foldwise.txt'\n",
    "data_dir = '../ICBHI_Dataset/audio_and_txt_files/'\n",
    "\n",
    "def Extract_Annotation_Data(file_name, data_dir):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data=[tokens], columns=['Patient Number', 'Recording index', 'Chest location', 'Acquisition mode', 'Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(data_dir, file_name + '.txt'), names=['Start', 'End', 'Crackles', 'Wheezes'], delimiter='\\t')\n",
    "    return recording_info, recording_annotations\n",
    "\n",
    "def get_annotations(data_dir):\n",
    "    filenames = [s.split('.')[0] for s in os.listdir(data_dir) if '.txt' in s]\n",
    "    i_list = []\n",
    "    rec_annotations_dict = {}\n",
    "    for s in filenames:\n",
    "        i, a = Extract_Annotation_Data(s, data_dir)\n",
    "        i_list.append(i)\n",
    "        rec_annotations_dict[s] = a\n",
    "    return filenames, rec_annotations_dict\n",
    "\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "    max_ind = len(raw_data)\n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind:end_ind]\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0:\n",
    "        return 0\n",
    "    elif crackle == 1 and wheeze == 0:\n",
    "        return 1\n",
    "    elif crackle == 0 and wheeze == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def get_sound_samples(recording_annotations, file_name, data_dir, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    data, rate = librosa.load(os.path.join(data_dir, file_name + '.wav'), sr=sample_rate)\n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start, end, get_label(crackles, wheezes)))\n",
    "    return sample_data\n",
    "\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "    S = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    S = (S - S.min()) / (S.max() - S.min())\n",
    "    S *= 255\n",
    "    S = cv2.applyColorMap(S.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    S = cv2.resize(S, (224, 224))  # Resize to a fixed size\n",
    "    return S\n",
    "\n",
    "def create_chroma(current_window, sample_rate):\n",
    "    chroma = librosa.feature.chroma_stft(y=current_window, sr=sample_rate)\n",
    "    chroma = (chroma - chroma.min()) / (chroma.max() - chroma.min())\n",
    "    chroma *= 255\n",
    "    chroma = cv2.applyColorMap(chroma.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    chroma = cv2.resize(chroma, (224, 224))  # Resize to a fixed size\n",
    "    return chroma\n",
    "\n",
    "def create_mfcc(current_window, sample_rate):\n",
    "    mfcc = librosa.feature.mfcc(y=current_window, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc = (mfcc - mfcc.min()) / (mfcc.max() - mfcc.min())\n",
    "    mfcc *= 255\n",
    "    mfcc = cv2.applyColorMap(mfcc.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    mfcc = cv2.resize(mfcc, (224, 224))  # Resize to a fixed size\n",
    "    return mfcc\n",
    "\n",
    "def save_image(array, save_path):\n",
    "    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Individual Cycles: 920it [00:10, 84.03it/s] \n"
     ]
    }
   ],
   "source": [
    "filenames, rec_annotations_dict = get_annotations(data_dir)\n",
    "\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [], []]\n",
    "for idx, file_name in tqdm(enumerate(filenames), desc=\"Extracting Individual Cycles\"):\n",
    "    data = get_sound_samples(rec_annotations_dict[file_name], file_name, data_dir, sample_rate)\n",
    "    cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, 0) for cycle_idx, d in enumerate(data[1:])]\n",
    "    cycle_list.extend(cycles_with_labels)\n",
    "    for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "        classwise_cycle_list[d[1]].append(d)\n",
    "\n",
    "# 데이터 증강\n",
    "scale = 1\n",
    "aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[0])\n",
    "for idx in range(aug_nos):\n",
    "    i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    normal_i = classwise_cycle_list[0][i]\n",
    "    normal_j = classwise_cycle_list[0][j]\n",
    "    new_sample = np.concatenate([normal_i[0], normal_j[0]])\n",
    "    cycle_list.append((new_sample, 0, normal_i[2] + '-' + normal_j[2], idx, 1))\n",
    "\n",
    "# 증강 함수 추가 (crackle, wheeze, both)\n",
    "def augment_class(class_index, classwise_cycle_list, scale):\n",
    "    aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[class_index])\n",
    "    for idx in range(aug_nos):\n",
    "        aug_prob = random.random()\n",
    "        if aug_prob < 0.6:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        elif aug_prob >= 0.6 and aug_prob < 0.8:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[0][j]\n",
    "        else:\n",
    "            i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[0][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        new_sample = np.concatenate([sample_i[0], sample_j[0]])\n",
    "        cycle_list.append((new_sample, class_index, sample_i[2] + '-' + sample_j[2], idx, 1))\n",
    "\n",
    "augment_class(1, classwise_cycle_list, scale)\n",
    "augment_class(2, classwise_cycle_list, scale)\n",
    "augment_class(3, classwise_cycle_list, scale)\n",
    "\n",
    "# 오디오 데이터 정렬\n",
    "desiredLength = 8\n",
    "output = []\n",
    "for idx, sample in enumerate(cycle_list):\n",
    "    output_buffer_length = int(desiredLength * sample_rate)\n",
    "    soundclip = sample[0].copy()\n",
    "    n_samples = len(soundclip)\n",
    "    if n_samples < output_buffer_length:\n",
    "        t = output_buffer_length // n_samples\n",
    "        d = output_buffer_length % n_samples\n",
    "        d = soundclip[:d]\n",
    "        repeat_sample = np.concatenate((np.tile(soundclip, t), d))\n",
    "        copy_repeat_sample = repeat_sample.copy()\n",
    "        output.append((copy_repeat_sample, sample[1]))\n",
    "    else:\n",
    "        copy_repeat_sample = soundclip[:output_buffer_length]\n",
    "        output.append((copy_repeat_sample, sample[1]))\n",
    "audio_data = output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images:   0%|          | 0/14568 [00:00<?, ?it/s]c:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Saving Images:   0%|          | 3/14568 [00:00<19:05, 12.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images: 100%|██████████| 14568/14568 [18:02<00:00, 13.46it/s]\n",
      "Saving Images in dir: 100%|██████████| 14568/14568 [02:31<00:00, 95.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mel-spectrogram, chroma, MFCC 이미지 생성 및 저장\n",
    "mel_img = []\n",
    "chroma_img = []\n",
    "mfcc_img = []\n",
    "for index in tqdm(range(len(audio_data)), desc=\"Saving Images\"):\n",
    "    audio = audio_data[index][0]\n",
    "    label = audio_data[index][1]\n",
    "    mel_image = create_mel_raw(audio, sample_rate, f_max=f_max, n_mels=n_mels, nfft=nfft, hop=hop, resz=1)\n",
    "    chroma_image = create_chroma(audio, sample_rate)\n",
    "    mfcc_image = create_mfcc(audio, sample_rate)\n",
    "    mel_img.append((mel_image, label))\n",
    "    chroma_img.append((chroma_image, label))\n",
    "    mfcc_img.append((mfcc_image, label))\n",
    "\n",
    "destination_dir = '../data_4gr'\n",
    "mel_dir = os.path.join(destination_dir, 'mel_image')\n",
    "chroma_dir = os.path.join(destination_dir, 'chroma_image')\n",
    "mfcc_dir = os.path.join(destination_dir, 'mfcc_image')\n",
    "\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "os.makedirs(chroma_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_dir, exist_ok=True)\n",
    "\n",
    "# Create the four folders for the labels in each image type directory\n",
    "for label in ['normal', 'crackle', 'wheeze', 'both']:\n",
    "    os.makedirs(os.path.join(mel_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(chroma_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(mfcc_dir, label), exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(len(mel_img)), desc=\"Saving Images in dir\"):\n",
    "    input_mel = mel_img[i][0]\n",
    "    input_chroma = chroma_img[i][0]\n",
    "    input_mfcc = mfcc_img[i][0]\n",
    "    label = mel_img[i][1]\n",
    "    \n",
    "    if label == 0:\n",
    "        mel_save_path = os.path.join(mel_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 1:\n",
    "        mel_save_path = os.path.join(mel_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 2:\n",
    "        mel_save_path = os.path.join(mel_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "    else:\n",
    "        mel_save_path = os.path.join(mel_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "    \n",
    "    cv2.imwrite(mel_save_path, cv2.cvtColor(input_mel, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(chroma_save_path, cv2.cvtColor(input_chroma, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(mfcc_save_path, cv2.cvtColor(input_mfcc, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICBHI image 분산, 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.7520, 0.4380, 0.1649]), Std: tensor([0.2788, 0.3732, 0.2812])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mel_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Mel-spectrogram Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma Mean: tensor([0.2995, 0.4973, 0.6374]), Std: tensor([0.3043, 0.3505, 0.2868])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/chroma_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Chroma Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC Mean: tensor([0.0714, 0.4974, 0.8972]), Std: tensor([0.1645, 0.2059, 0.2028])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mfcc_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'MFCC Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel-spectrogram old Mean: tensor([0.3416, 0.1199, 0.3481]), Std: tensor([0.2769, 0.1272, 0.1512])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mel_image_old', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Mel-spectrogram old Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
