{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "\n",
    "mel_dir = '../data_4gr/mel_image'\n",
    "chroma_dir = '../data_4gr/chroma_image'\n",
    "mfcc_dir = '../data_4gr/mfcc_image'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC, Chroma, Mel-spectrogram from ICBHI Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Seed 설정\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "# 설정값\n",
    "sample_rate = 16000\n",
    "desired_length = 5\n",
    "n_mels = 64\n",
    "nfft = 2048\n",
    "hop = 512\n",
    "f_max = 4000\n",
    "\n",
    "# 파일 경로\n",
    "folds_file = '../ICBHI_Dataset/patient_list_foldwise.txt'\n",
    "data_dir = '../ICBHI_Dataset/audio_and_txt_files/'\n",
    "\n",
    "def Extract_Annotation_Data(file_name, data_dir):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data=[tokens], columns=['Patient Number', 'Recording index', 'Chest location', 'Acquisition mode', 'Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(data_dir, file_name + '.txt'), names=['Start', 'End', 'Crackles', 'Wheezes'], delimiter='\\t')\n",
    "    return recording_info, recording_annotations\n",
    "\n",
    "def get_annotations(data_dir):\n",
    "    filenames = [s.split('.')[0] for s in os.listdir(data_dir) if '.txt' in s]\n",
    "    i_list = []\n",
    "    rec_annotations_dict = {}\n",
    "    for s in filenames:\n",
    "        i, a = Extract_Annotation_Data(s, data_dir)\n",
    "        i_list.append(i)\n",
    "        rec_annotations_dict[s] = a\n",
    "    return filenames, rec_annotations_dict\n",
    "\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "    max_ind = len(raw_data)\n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind:end_ind]\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0:\n",
    "        return 0\n",
    "    elif crackle == 1 and wheeze == 0:\n",
    "        return 1\n",
    "    elif crackle == 0 and wheeze == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def get_sound_samples(recording_annotations, file_name, data_dir, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    data, rate = librosa.load(os.path.join(data_dir, file_name + '.wav'), sr=sample_rate)\n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start, end, get_label(crackles, wheezes)))\n",
    "    return sample_data\n",
    "\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "    S = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    S = (S - S.min()) / (S.max() - S.min())\n",
    "    S *= 255\n",
    "    S = cv2.applyColorMap(S.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    S = cv2.resize(S, (224, 224))  # Resize to a fixed size\n",
    "    return S\n",
    "\n",
    "def create_chroma(current_window, sample_rate):\n",
    "    chroma = librosa.feature.chroma_stft(y=current_window, sr=sample_rate)\n",
    "    chroma = (chroma - chroma.min()) / (chroma.max() - chroma.min())\n",
    "    chroma *= 255\n",
    "    chroma = cv2.applyColorMap(chroma.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    chroma = cv2.resize(chroma, (224, 224))  # Resize to a fixed size\n",
    "    return chroma\n",
    "\n",
    "def create_mfcc(current_window, sample_rate):\n",
    "    mfcc = librosa.feature.mfcc(y=current_window, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc = (mfcc - mfcc.min()) / (mfcc.max() - mfcc.min())\n",
    "    mfcc *= 255\n",
    "    mfcc = cv2.applyColorMap(mfcc.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    mfcc = cv2.resize(mfcc, (224, 224))  # Resize to a fixed size\n",
    "    return mfcc\n",
    "\n",
    "def save_image(array, save_path):\n",
    "    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Individual Cycles: 920it [00:10, 84.03it/s] \n"
     ]
    }
   ],
   "source": [
    "filenames, rec_annotations_dict = get_annotations(data_dir)\n",
    "\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [], []]\n",
    "for idx, file_name in tqdm(enumerate(filenames), desc=\"Extracting Individual Cycles\"):\n",
    "    data = get_sound_samples(rec_annotations_dict[file_name], file_name, data_dir, sample_rate)\n",
    "    cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, 0) for cycle_idx, d in enumerate(data[1:])]\n",
    "    cycle_list.extend(cycles_with_labels)\n",
    "    for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "        classwise_cycle_list[d[1]].append(d)\n",
    "\n",
    "# 데이터 증강\n",
    "scale = 1\n",
    "aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[0])\n",
    "for idx in range(aug_nos):\n",
    "    i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    normal_i = classwise_cycle_list[0][i]\n",
    "    normal_j = classwise_cycle_list[0][j]\n",
    "    new_sample = np.concatenate([normal_i[0], normal_j[0]])\n",
    "    cycle_list.append((new_sample, 0, normal_i[2] + '-' + normal_j[2], idx, 1))\n",
    "\n",
    "# 증강 함수 추가 (crackle, wheeze, both)\n",
    "def augment_class(class_index, classwise_cycle_list, scale):\n",
    "    aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[class_index])\n",
    "    for idx in range(aug_nos):\n",
    "        aug_prob = random.random()\n",
    "        if aug_prob < 0.6:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        elif aug_prob >= 0.6 and aug_prob < 0.8:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[0][j]\n",
    "        else:\n",
    "            i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[0][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        new_sample = np.concatenate([sample_i[0], sample_j[0]])\n",
    "        cycle_list.append((new_sample, class_index, sample_i[2] + '-' + sample_j[2], idx, 1))\n",
    "\n",
    "augment_class(1, classwise_cycle_list, scale)\n",
    "augment_class(2, classwise_cycle_list, scale)\n",
    "augment_class(3, classwise_cycle_list, scale)\n",
    "\n",
    "# 오디오 데이터 정렬\n",
    "desiredLength = 8\n",
    "output = []\n",
    "for idx, sample in enumerate(cycle_list):\n",
    "    output_buffer_length = int(desiredLength * sample_rate)\n",
    "    soundclip = sample[0].copy()\n",
    "    n_samples = len(soundclip)\n",
    "    if n_samples < output_buffer_length:\n",
    "        t = output_buffer_length // n_samples\n",
    "        d = output_buffer_length % n_samples\n",
    "        d = soundclip[:d]\n",
    "        repeat_sample = np.concatenate((np.tile(soundclip, t), d))\n",
    "        copy_repeat_sample = repeat_sample.copy()\n",
    "        output.append((copy_repeat_sample, sample[1]))\n",
    "    else:\n",
    "        copy_repeat_sample = soundclip[:output_buffer_length]\n",
    "        output.append((copy_repeat_sample, sample[1]))\n",
    "audio_data = output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images:   0%|          | 0/14568 [00:00<?, ?it/s]c:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Saving Images:   0%|          | 3/14568 [00:00<19:05, 12.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images: 100%|██████████| 14568/14568 [18:02<00:00, 13.46it/s]\n",
      "Saving Images in dir: 100%|██████████| 14568/14568 [02:31<00:00, 95.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mel-spectrogram, chroma, MFCC 이미지 생성 및 저장\n",
    "mel_img = []\n",
    "chroma_img = []\n",
    "mfcc_img = []\n",
    "for index in tqdm(range(len(audio_data)), desc=\"Saving Images\"):\n",
    "    audio = audio_data[index][0]\n",
    "    label = audio_data[index][1]\n",
    "    mel_image = create_mel_raw(audio, sample_rate, f_max=f_max, n_mels=n_mels, nfft=nfft, hop=hop, resz=1)\n",
    "    chroma_image = create_chroma(audio, sample_rate)\n",
    "    mfcc_image = create_mfcc(audio, sample_rate)\n",
    "    mel_img.append((mel_image, label))\n",
    "    chroma_img.append((chroma_image, label))\n",
    "    mfcc_img.append((mfcc_image, label))\n",
    "\n",
    "destination_dir = '../data_4gr'\n",
    "mel_dir = os.path.join(destination_dir, 'mel_image')\n",
    "chroma_dir = os.path.join(destination_dir, 'chroma_image')\n",
    "mfcc_dir = os.path.join(destination_dir, 'mfcc_image')\n",
    "\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "os.makedirs(chroma_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_dir, exist_ok=True)\n",
    "\n",
    "# Create the four folders for the labels in each image type directory\n",
    "for label in ['normal', 'crackle', 'wheeze', 'both']:\n",
    "    os.makedirs(os.path.join(mel_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(chroma_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(mfcc_dir, label), exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(len(mel_img)), desc=\"Saving Images in dir\"):\n",
    "    input_mel = mel_img[i][0]\n",
    "    input_chroma = chroma_img[i][0]\n",
    "    input_mfcc = mfcc_img[i][0]\n",
    "    label = mel_img[i][1]\n",
    "    \n",
    "    if label == 0:\n",
    "        mel_save_path = os.path.join(mel_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 1:\n",
    "        mel_save_path = os.path.join(mel_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 2:\n",
    "        mel_save_path = os.path.join(mel_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "    else:\n",
    "        mel_save_path = os.path.join(mel_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        chroma_save_path = os.path.join(chroma_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        mfcc_save_path = os.path.join(mfcc_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "    \n",
    "    cv2.imwrite(mel_save_path, cv2.cvtColor(input_mel, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(chroma_save_path, cv2.cvtColor(input_chroma, cv2.COLOR_RGB2BGR))\n",
    "    cv2.imwrite(mfcc_save_path, cv2.cvtColor(input_mfcc, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICBHI image 분산, 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.7520, 0.4380, 0.1649]), Std: tensor([0.2788, 0.3732, 0.2812])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mel_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Mel-spectrogram Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma Mean: tensor([0.2995, 0.4973, 0.6374]), Std: tensor([0.3043, 0.3505, 0.2868])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/chroma_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Chroma Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC Mean: tensor([0.0714, 0.4974, 0.8972]), Std: tensor([0.1645, 0.2059, 0.2028])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mfcc_image', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'MFCC Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mel-spectrogram old Mean: tensor([0.3416, 0.1199, 0.3481]), Std: tensor([0.2769, 0.1272, 0.1512])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root='../data_4gr/mel_image_old', transform=transforms.ToTensor())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data in loader:\n",
    "    batch = data[0]\n",
    "    batch_samples = batch.size(0)\n",
    "    batch = batch.view(batch_samples, batch.size(1), -1)\n",
    "    mean += batch.mean(2).sum(0)\n",
    "    std += batch.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Mel-spectrogram old Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDLINet\n",
    "- remove baseline wandering\n",
    "- pitch shifting\n",
    "- add noise\n",
    "- normalize signal\n",
    "- sample rate 4000\n",
    "- nfft 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khsfu\\AppData\\Local\\Temp\\ipykernel_30060\\753782967.py:16: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import cmapy\n",
    "\n",
    "# Seed 설정\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "\n",
    "# 설정값\n",
    "sample_rate = 16000 #4000\n",
    "desired_length = 5\n",
    "n_mels = 64\n",
    "nfft = 2048 #1024\n",
    "hop = 512\n",
    "f_max = 4000\n",
    "\n",
    "# 파일 경로\n",
    "folds_file = '../ICBHI_Dataset/patient_list_foldwise.txt'\n",
    "data_dir = '../ICBHI_Dataset/audio_and_txt_files/'\n",
    "mel_dir = '../data_4gr/mel_image_rdlinet'\n",
    "chroma_dir = '../data_4gr/chroma_image_rdlinet'\n",
    "mfcc_dir = '../data_4gr/mfcc_image_rdlinet'\n",
    "\n",
    "def Extract_Annotation_Data(file_name, data_dir):\n",
    "    tokens = file_name.split('_')\n",
    "    recording_info = pd.DataFrame(data=[tokens], columns=['Patient Number', 'Recording index', 'Chest location', 'Acquisition mode', 'Recording equipment'])\n",
    "    recording_annotations = pd.read_csv(os.path.join(data_dir, file_name + '.txt'), names=['Start', 'End', 'Crackles', 'Wheezes'], delimiter='\\t')\n",
    "    return recording_info, recording_annotations\n",
    "\n",
    "def get_annotations(data_dir):\n",
    "    filenames = [s.split('.')[0] for s in os.listdir(data_dir) if '.txt' in s]\n",
    "    i_list = []\n",
    "    rec_annotations_dict = {}\n",
    "    for s in filenames:\n",
    "        i, a = Extract_Annotation_Data(s, data_dir)\n",
    "        i_list.append(i)\n",
    "        rec_annotations_dict[s] = a\n",
    "    return filenames, rec_annotations_dict\n",
    "\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "    max_ind = len(raw_data)\n",
    "    start_ind = min(int(start * sample_rate), max_ind)\n",
    "    end_ind = min(int(end * sample_rate), max_ind)\n",
    "    return raw_data[start_ind:end_ind]\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "    if crackle == 0 and wheeze == 0:\n",
    "        return 0\n",
    "    elif crackle == 1 and wheeze == 0:\n",
    "        return 1\n",
    "    elif crackle == 0 and wheeze == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def get_sound_samples(recording_annotations, file_name, data_dir, sample_rate):\n",
    "    sample_data = [file_name]\n",
    "    data, rate = librosa.load(os.path.join(data_dir, file_name + '.wav'), sr=sample_rate)\n",
    "    for i in range(len(recording_annotations.index)):\n",
    "        row = recording_annotations.loc[i]\n",
    "        start = row['Start']\n",
    "        end = row['End']\n",
    "        crackles = row['Crackles']\n",
    "        wheezes = row['Wheezes']\n",
    "        audio_chunk = slice_data(start, end, data, rate)\n",
    "        sample_data.append((audio_chunk, start, end, get_label(crackles, wheezes)))\n",
    "    return sample_data\n",
    "\n",
    "def remove_baseline_wandering(signal, sample_rate):\n",
    "    n = len(signal)\n",
    "    freq = np.fft.fftfreq(n, d=1/sample_rate)\n",
    "    fft_signal = np.fft.fft(signal)\n",
    "    fft_signal[np.abs(freq) < 1] = 0  # Remove frequencies below 1 Hz\n",
    "    filtered_signal = np.fft.ifft(fft_signal)\n",
    "    return np.real(filtered_signal)\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    return signal / np.max(np.abs(signal))\n",
    "\n",
    "def pitch_shift(signal, sr, n_steps):\n",
    "    return librosa.effects.pitch_shift(signal, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def add_noise(signal, snr):\n",
    "    noise = np.random.normal(0, 1, signal.shape)\n",
    "    signal_power = np.mean(signal**2)\n",
    "    noise_power = signal_power / (10**(snr / 10))\n",
    "    noise = noise * np.sqrt(noise_power)\n",
    "    return signal + noise\n",
    "\n",
    "\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "    S = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "    S = librosa.power_to_db(S, ref=np.max)\n",
    "    S = (S - S.min()) / (S.max() - S.min())\n",
    "    S *= 255\n",
    "    S = cv2.applyColorMap(S.astype(np.uint8), cmapy.cmap('plasma'))\n",
    "    S = cv2.resize(S, (224, 224))  # Resize to a fixed size\n",
    "    S = cv2.flip(S, 0)\n",
    "    return S\n",
    "\n",
    "def create_chroma(current_window, sample_rate):\n",
    "    chroma = librosa.feature.chroma_stft(y=current_window, sr=sample_rate)\n",
    "    chroma = (chroma - chroma.min()) / (chroma.max() - chroma.min())\n",
    "    chroma *= 255\n",
    "    chroma = cv2.applyColorMap(chroma.astype(np.uint8), cmapy.cmap('inferno'))\n",
    "    chroma = cv2.resize(chroma, (224, 224))  # Resize to a fixed size\n",
    "    chroma = cv2.flip(chroma, 0)\n",
    "    return chroma\n",
    "\n",
    "def create_mfcc(current_window, sample_rate):\n",
    "    mfcc = librosa.feature.mfcc(y=current_window, sr=sample_rate, n_mfcc=13)\n",
    "    mfcc = (mfcc - mfcc.min()) / (mfcc.max() - mfcc.min())\n",
    "    mfcc *= 255\n",
    "    mfcc = cv2.applyColorMap(mfcc.astype(np.uint8), cmapy.cmap('viridis'))\n",
    "    mfcc = cv2.resize(mfcc, (224, 224))  # Resize to a fixed size\n",
    "    mfcc = cv2.flip(mfcc, 0)\n",
    "    return mfcc\n",
    "\n",
    "def save_image(array, save_path):\n",
    "    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Individual Cycles: 920it [00:10, 84.27it/s] \n",
      "Audio augmenting: 14568it [41:41,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_data_parts\\audio_data_part_0.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_1.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_2.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_3.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_4.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_5.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_6.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_7.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_8.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_9.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_10.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_11.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_12.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_13.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_14.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_15.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_16.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_17.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_18.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_19.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_20.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_21.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_22.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_23.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_24.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_25.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_26.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_27.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_28.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_29.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_30.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_31.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_32.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_33.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_34.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_35.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_36.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_37.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_38.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_39.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_40.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_41.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_42.pkl 저장 완료\n",
      "audio_data_parts\\audio_data_part_43.pkl 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filenames, rec_annotations_dict = get_annotations(data_dir)\n",
    "\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [], []]\n",
    "for idx, file_name in tqdm(enumerate(filenames), desc=\"Extracting Individual Cycles\"):\n",
    "    data = get_sound_samples(rec_annotations_dict[file_name], file_name, data_dir, sample_rate)\n",
    "    cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, 0) for cycle_idx, d in enumerate(data[1:])]\n",
    "    cycle_list.extend(cycles_with_labels)\n",
    "    for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "        classwise_cycle_list[d[1]].append(d)\n",
    "\n",
    "# 데이터 증강\n",
    "scale = 1\n",
    "aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[0])\n",
    "for idx in range(aug_nos):\n",
    "    i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "    normal_i = classwise_cycle_list[0][i]\n",
    "    normal_j = classwise_cycle_list[0][j]\n",
    "    new_sample = np.concatenate([normal_i[0], normal_j[0]])\n",
    "    cycle_list.append((new_sample, 0, normal_i[2] + '-' + normal_j[2], idx, 1))\n",
    "\n",
    "# 증강 함수 추가 (crackle, wheeze, both)\n",
    "def augment_class(class_index, classwise_cycle_list, scale):\n",
    "    aug_nos = scale * len(classwise_cycle_list[0]) - len(classwise_cycle_list[class_index])\n",
    "    for idx in range(aug_nos):\n",
    "        aug_prob = random.random()\n",
    "        if aug_prob < 0.6:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        elif aug_prob >= 0.6 and aug_prob < 0.8:\n",
    "            i = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            sample_i = classwise_cycle_list[class_index][i]\n",
    "            sample_j = classwise_cycle_list[0][j]\n",
    "        else:\n",
    "            i = random.randint(0, len(classwise_cycle_list[0]) - 1)\n",
    "            j = random.randint(0, len(classwise_cycle_list[class_index]) - 1)\n",
    "            sample_i = classwise_cycle_list[0][i]\n",
    "            sample_j = classwise_cycle_list[class_index][j]\n",
    "        new_sample = np.concatenate([sample_i[0], sample_j[0]])\n",
    "        cycle_list.append((new_sample, class_index, sample_i[2] + '-' + sample_j[2], idx, 1))\n",
    "\n",
    "augment_class(1, classwise_cycle_list, scale)\n",
    "augment_class(2, classwise_cycle_list, scale)\n",
    "augment_class(3, classwise_cycle_list, scale)\n",
    "\n",
    "# 오디오 데이터 정렬\n",
    "desiredLength = 8\n",
    "output = []\n",
    "for idx, sample in tqdm(enumerate(cycle_list), desc=\"Audio augmenting\"):\n",
    "    output_buffer_length = int(desiredLength * sample_rate)\n",
    "    soundclip = sample[0].copy()\n",
    "    n_samples = len(soundclip)\n",
    "    if n_samples < output_buffer_length:\n",
    "        t = output_buffer_length // n_samples\n",
    "        d = output_buffer_length % n_samples\n",
    "        d = soundclip[:d]\n",
    "        repeat_sample = np.concatenate((np.tile(soundclip, t), d))\n",
    "        copy_repeat_sample = repeat_sample.copy()\n",
    "        # output.append((copy_repeat_sample, sample[1]))\n",
    "    else:\n",
    "        copy_repeat_sample = soundclip[:output_buffer_length]\n",
    "        # output.append((copy_repeat_sample, sample[1]))\n",
    "    # print('before sample type: ', type(copy_repeat_sample))\n",
    "    # Baseline Wandering removal\n",
    "    # 전처리: 베이스라인 방황 제거 및 정규화\n",
    "    copy_repeat_sample = remove_baseline_wandering(copy_repeat_sample, sample_rate)\n",
    "    copy_repeat_sample = normalize_signal(copy_repeat_sample)\n",
    "    \n",
    "    # 원본 신호 추가\n",
    "    output.append((copy_repeat_sample, sample[1]))\n",
    "\n",
    "    # 증강: 피치 변환 및 노이즈 추가\n",
    "    augmented_sample = pitch_shift(copy_repeat_sample, sample_rate, -2)\n",
    "    output.append((augmented_sample, sample[1]))\n",
    "    # for n_steps in [-2, 1]:\n",
    "    #     augmented_sample = pitch_shift(copy_repeat_sample, sample_rate, n_steps)\n",
    "    #     output.append((augmented_sample, sample[1]))\n",
    "\n",
    "    augmented_sample = add_noise(copy_repeat_sample, 10)\n",
    "    output.append((augmented_sample, sample[1]))\n",
    "\n",
    "audio_data = output\n",
    "\n",
    "\n",
    "# 데이터 저장 디렉토리 설정\n",
    "save_dir = 'audio_data_parts'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 나눠서 저장\n",
    "part_size = 1000  # 한 파일에 저장할 샘플 수\n",
    "for i in range(0, len(audio_data), part_size):\n",
    "    part = audio_data[i:i + part_size]\n",
    "    part_file = os.path.join(save_dir, f'audio_data_part_{i//part_size}.pkl')\n",
    "    with open(part_file, 'wb') as f:\n",
    "        pickle.dump(part, f)\n",
    "    print(f'{part_file} 저장 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_data_part_0.pkl 불러오기 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images audio_data_part_0.pkl: 100%|██████████| 1000/1000 [04:22<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_data_part_1.pkl 불러오기 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images audio_data_part_1.pkl: 100%|██████████| 1000/1000 [03:55<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_data_part_10.pkl 불러오기 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images audio_data_part_10.pkl:  52%|█████▏    | 523/1000 [02:24<02:11,  3.62it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(audio_data_part)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving Images \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     14\u001b[0m     audio, label \u001b[38;5;241m=\u001b[39m audio_data_part[index]\n\u001b[1;32m---> 15\u001b[0m     mel_image \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_mel_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# 이미지 저장\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[3], line 102\u001b[0m, in \u001b[0;36mcreate_mel_raw\u001b[1;34m(current_window, sample_rate, n_mels, f_min, f_max, nfft, hop, resz)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mel_raw\u001b[39m(current_window, sample_rate, n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, f_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, f_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, nfft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, hop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, resz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 102\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     S \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(S, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m    104\u001b[0m     S \u001b[38;5;241m=\u001b[39m (S \u001b[38;5;241m-\u001b[39m S\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (S\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m S\u001b[38;5;241m.\u001b[39mmin())\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\feature\\spectral.py:2130\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2010\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \n\u001b[0;32m   2024\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2130\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2142\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\spectrum.py:2822\u001b[0m, in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m   2818\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2819\u001b[0m         )\n\u001b[0;32m   2820\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2821\u001b[0m         np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[1;32m-> 2822\u001b[0m             \u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2823\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2824\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2825\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2826\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2827\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2828\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2829\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2830\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2831\u001b[0m         )\n\u001b[0;32m   2832\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m   2833\u001b[0m     )\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\spectrum.py:378\u001b[0m, in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode, out)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bl_s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], n_columns):\n\u001b[0;32m    376\u001b[0m     bl_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(bl_s \u001b[38;5;241m+\u001b[39m n_columns, y_frames\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 378\u001b[0m     stft_matrix[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, bl_s \u001b[38;5;241m+\u001b[39m off_start : bl_t \u001b[38;5;241m+\u001b[39m off_start] \u001b[38;5;241m=\u001b[39m \u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfft_window\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbl_s\u001b[49m\u001b[43m:\u001b[49m\u001b[43mbl_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stft_matrix\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mrfft\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 저장된 데이터 파일 리스트\n",
    "save_dir = 'audio_data_parts'\n",
    "part_files = sorted(os.listdir(save_dir))\n",
    "\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "print(mel_dir)\n",
    "\n",
    "# 각 파일을 하나씩 불러와서 이미지 생성 및 저장\n",
    "for part_file in part_files:\n",
    "    with open(os.path.join(save_dir, part_file), 'rb') as f:\n",
    "        audio_data_part = pickle.load(f)\n",
    "    \n",
    "    print(f'{part_file} 불러오기 완료')\n",
    "\n",
    "     # 이미지 생성 및 저장\n",
    "    for index in tqdm(range(len(audio_data_part)), desc=f\"Saving Images {part_file}\"):\n",
    "        audio, label = audio_data_part[index]\n",
    "        mel_image = create_mel_raw(audio, sample_rate, f_max=f_max, n_mels=n_mels, nfft=nfft, hop=hop, resz=1)\n",
    "\n",
    "        # 이미지 저장\n",
    "        if label == 0:\n",
    "            mel_save_path = os.path.join(mel_dir, 'normal', f'image_{part_file}_{index}.jpg')\n",
    "        elif label == 1:\n",
    "            mel_save_path = os.path.join(mel_dir, 'crackle', f'image_{part_file}_{index}.jpg')\n",
    "        elif label == 2:\n",
    "            mel_save_path = os.path.join(mel_dir, 'wheeze', f'image_{part_file}_{index}.jpg')\n",
    "        else:\n",
    "            mel_save_path = os.path.join(mel_dir, 'both', f'image_{part_file}_{index}.jpg')\n",
    "        \n",
    "        cv2.imwrite(mel_save_path, cv2.cvtColor(mel_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving Images:  44%|████▍     | 19169/43704 [54:25<1:09:39,  5.87it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.96 MiB for an array with shape (1025, 251) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m audio \u001b[38;5;241m=\u001b[39m audio_data[index][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m label \u001b[38;5;241m=\u001b[39m audio_data[index][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m mel_image \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_mel_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# chroma_image = create_chroma(audio, sample_rate)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# mfcc_image = create_mfcc(audio, sample_rate)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m mel_img\u001b[38;5;241m.\u001b[39mappend((mel_image, label))\n",
      "Cell \u001b[1;32mIn[1], line 102\u001b[0m, in \u001b[0;36mcreate_mel_raw\u001b[1;34m(current_window, sample_rate, n_mels, f_min, f_max, nfft, hop, resz)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_mel_raw\u001b[39m(current_window, sample_rate, n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, f_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, f_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m, nfft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, hop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, resz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 102\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m     S \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mpower_to_db(S, ref\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m    104\u001b[0m     S \u001b[38;5;241m=\u001b[39m (S \u001b[38;5;241m-\u001b[39m S\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (S\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m S\u001b[38;5;241m.\u001b[39mmin())\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\feature\\spectral.py:2130\u001b[0m, in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   2008\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmelspectrogram\u001b[39m(\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2010\u001b[0m     y: Optional[np\u001b[38;5;241m.\u001b[39mndarray] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute a mel-scaled spectrogram.\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \n\u001b[0;32m   2024\u001b[0m \u001b[38;5;124;03m    If a spectrogram input ``S`` is provided, then it is mapped directly onto\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;124;03m    >>> ax.set(title='Mel-frequency spectrogram')\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2130\u001b[0m     S, n_fft \u001b[38;5;241m=\u001b[39m \u001b[43m_spectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2142\u001b[0m     \u001b[38;5;66;03m# Build a Mel filter\u001b[39;00m\n\u001b[0;32m   2143\u001b[0m     mel_basis \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mmel(sr\u001b[38;5;241m=\u001b[39msr, n_fft\u001b[38;5;241m=\u001b[39mn_fft, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\khsfu\\anaconda3\\envs\\icbhi\\Lib\\site-packages\\librosa\\core\\spectrum.py:2821\u001b[0m, in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParameterError(\n\u001b[0;32m   2818\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal must be provided to compute a spectrogram\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2819\u001b[0m         )\n\u001b[0;32m   2820\u001b[0m     S \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 2821\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2822\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2823\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2824\u001b[0m \u001b[43m                \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2825\u001b[0m \u001b[43m                \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2826\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2827\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2828\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2829\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2830\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2832\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m power\n\u001b[0;32m   2833\u001b[0m     )\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m S, n_fft\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.96 MiB for an array with shape (1025, 251) and data type float64"
     ]
    }
   ],
   "source": [
    "# mel-spectrogram, chroma, MFCC 이미지 생성 및 저장\n",
    "mel_img = []\n",
    "chroma_img = []\n",
    "mfcc_img = []\n",
    "for index in tqdm(range(len(audio_data)), desc=\"Saving Images\"):\n",
    "    audio = audio_data[index][0]\n",
    "    label = audio_data[index][1]\n",
    "    mel_image = create_mel_raw(audio, sample_rate, f_max=f_max, n_mels=n_mels, nfft=nfft, hop=hop, resz=1)\n",
    "    # chroma_image = create_chroma(audio, sample_rate)\n",
    "    # mfcc_image = create_mfcc(audio, sample_rate)\n",
    "    mel_img.append((mel_image, label))\n",
    "    # chroma_img.append((chroma_image, label))\n",
    "    # mfcc_img.append((mfcc_image, label))\n",
    "\n",
    "# destination_dir = '../data_4gr'\n",
    "# mel_dir = os.path.join(destination_dir, 'mel_image')\n",
    "# chroma_dir = os.path.join(destination_dir, 'chroma_image')\n",
    "# mfcc_dir = os.path.join(destination_dir, 'mfcc_image')\n",
    "\n",
    "os.makedirs(mel_dir, exist_ok=True)\n",
    "os.makedirs(chroma_dir, exist_ok=True)\n",
    "os.makedirs(mfcc_dir, exist_ok=True)\n",
    "\n",
    "# Create the four folders for the labels in each image type directory\n",
    "for label in ['normal', 'crackle', 'wheeze', 'both']:\n",
    "    os.makedirs(os.path.join(mel_dir, label), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(chroma_dir, label), exist_ok=True)\n",
    "    # os.makedirs(os.path.join(mfcc_dir, label), exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(len(mel_img)), desc=\"Saving Images in dir\"):\n",
    "    input_mel = mel_img[i][0]\n",
    "    # input_chroma = chroma_img[i][0]\n",
    "    # input_mfcc = mfcc_img[i][0]\n",
    "    label = mel_img[i][1]\n",
    "    \n",
    "    if label == 0:\n",
    "        mel_save_path = os.path.join(mel_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        # chroma_save_path = os.path.join(chroma_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "        # mfcc_save_path = os.path.join(mfcc_dir, 'normal', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 1:\n",
    "        mel_save_path = os.path.join(mel_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        # chroma_save_path = os.path.join(chroma_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "        # mfcc_save_path = os.path.join(mfcc_dir, 'crackle', 'image_'+str(i)+'.jpg')\n",
    "    elif label == 2:\n",
    "        mel_save_path = os.path.join(mel_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        # chroma_save_path = os.path.join(chroma_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "        # mfcc_save_path = os.path.join(mfcc_dir, 'wheeze', 'image_'+str(i)+'.jpg')\n",
    "    else:\n",
    "        mel_save_path = os.path.join(mel_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        # chroma_save_path = os.path.join(chroma_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "        # mfcc_save_path = os.path.join(mfcc_dir, 'both', 'image_'+str(i)+'.jpg')\n",
    "    \n",
    "    cv2.imwrite(mel_save_path, cv2.cvtColor(input_mel, cv2.COLOR_RGB2BGR))\n",
    "    # cv2.imwrite(chroma_save_path, cv2.cvtColor(input_chroma, cv2.COLOR_RGB2BGR))\n",
    "    # cv2.imwrite(mfcc_save_path, cv2.cvtColor(input_mfcc, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
