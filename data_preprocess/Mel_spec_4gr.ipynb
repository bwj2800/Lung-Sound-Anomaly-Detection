{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebea4f-ce93-4fc6-bbbd-79070f50124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import peak_widths\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse.csgraph import min_weight_full_bipartite_matching\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2bc368-146d-40ac-b20c-5a9c26af880c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "desired_length = 5\n",
    "n_mels = 64\n",
    "nfft = 256\n",
    "hop = nfft//2\n",
    "f_max = 2000\n",
    "stetho_id=-1\n",
    "folds_file = './ICBHI_Dataset/patient_list_foldwise.txt'\n",
    "# train_flag = train_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d87564-4b55-4f2d-a6ea-4bdeff15dcdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_dir = './ICBHI_Dataset/audio_and_txt_files/'\n",
    "# file_name = './Dataset/audio_and_txt_files/'\n",
    "def Extract_Annotation_Data(file_name, data_dir):\n",
    "\ttokens = file_name.split('_')\n",
    "\trecording_info = pd.DataFrame(data = [tokens], columns = ['Patient Number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
    "\trecording_annotations = pd.read_csv(os.path.join(data_dir, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
    "\treturn recording_info, recording_annotations\n",
    "\n",
    "# get annotations data and filenames\n",
    "def get_annotations(data_dir):\n",
    "\tfilenames = [s.split('.')[0] for s in os.listdir(data_dir) if '.txt' in s]\n",
    "\ti_list = []\n",
    "\trec_annotations_dict = {}\n",
    "\tfor s in filenames:\n",
    "\t\ti,a = Extract_Annotation_Data(s, data_dir)\n",
    "\t\ti_list.append(i)\n",
    "\t\trec_annotations_dict[s] = a\n",
    "\n",
    "\trecording_info = pd.concat(i_list, axis = 0)\n",
    "\trecording_info.head()\n",
    "\n",
    "\treturn filenames, rec_annotations_dict\n",
    "\n",
    "\n",
    "\n",
    "def slice_data(start, end, raw_data, sample_rate):\n",
    "\tmax_ind = len(raw_data) \n",
    "\tstart_ind = min(int(start * sample_rate), max_ind)\n",
    "\tend_ind = min(int(end * sample_rate), max_ind)\n",
    "\treturn raw_data[start_ind: end_ind]\n",
    "\n",
    "def get_label(crackle, wheeze):\n",
    "\tif crackle == 0 and wheeze == 0:\n",
    "\t\treturn 0\n",
    "\telif crackle == 1 and wheeze == 0:\n",
    "\t\treturn 1\n",
    "\telif crackle == 0 and wheeze == 1:\n",
    "\t\treturn 2\n",
    "\telse:\n",
    "\t\treturn 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55ee19-fb83-4dc7-bd9f-71c9731b7d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sound_samples(recording_annotations, file_name, data_dir, sample_rate):\n",
    "\tsample_data = [file_name]\n",
    "\t# load file with specified sample rate (also converts to mono)\n",
    "\tdata, rate = librosa.load(os.path.join(data_dir, file_name+'.wav'), sr=sample_rate)\n",
    "\t#print(\"Sample Rate\", rate)\n",
    "\t\n",
    "\tfor i in range(len(recording_annotations.index)):\n",
    "\t\trow = recording_annotations.loc[i]\n",
    "\t\tstart = row['Start']\n",
    "\t\tend = row['End']\n",
    "\t\tcrackles = row['Crackles']\n",
    "\t\twheezes = row['Wheezes']\n",
    "\t\taudio_chunk = slice_data(start, end, data, rate)\n",
    "\t\tsample_data.append((audio_chunk, start,end, get_label(crackles, wheezes)))\n",
    "\treturn sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37888b-526f-4432-b265-69c425a04cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filenames, rec_annotations_dict = get_annotations(data_dir)\n",
    "# print(rec_annotations_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d2d27-0085-47e4-b341-15480b4e2015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "filenames_with_labels = []\n",
    "print(\"Exracting Individual Cycles\")\n",
    "cycle_list = []\n",
    "classwise_cycle_list = [[], [], [],[]]\n",
    "for idx, file_name in tqdm(enumerate(filenames)):\n",
    "    data = get_sound_samples(rec_annotations_dict[file_name], file_name, data_dir, sample_rate)\n",
    "    # print('--------', data)\n",
    "    cycles_with_labels = [(d[0], d[3], file_name, cycle_idx, d[3]) for cycle_idx, d in enumerate(data[1:])] #lable: d[3]\n",
    "    # print('cycles_with_labels: ', cycles_with_labels)\n",
    "    cycle_list.extend(cycles_with_labels)\n",
    "    for cycle_idx, d in enumerate(cycles_with_labels):\n",
    "        filenames_with_labels.append(file_name+'_'+str(d[3])+'_'+str(d[1]))\n",
    "        classwise_cycle_list[d[1]].append(d)\n",
    "print(len(cycle_list))\n",
    "print(len(classwise_cycle_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f86951-a521-4373-bd80-c5425c6ec319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# augment normal\n",
    "seed_value = 1\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)\n",
    "scale = 1\n",
    "aug_nos = scale*len(classwise_cycle_list[0]) - len(classwise_cycle_list[0])\n",
    "for idx in range(aug_nos):\n",
    "    # normal_i + normal_j\n",
    "    i = random.randint(0, len(classwise_cycle_list[0])-1)\n",
    "    j = random.randint(0, len(classwise_cycle_list[0])-1)\n",
    "    normal_i = classwise_cycle_list[0][i]\n",
    "    normal_j = classwise_cycle_list[0][j]\n",
    "    new_sample = np.concatenate([normal_i[0], normal_j[0]])\n",
    "    cycle_list.append((new_sample, 0, normal_i[2]+'-'+normal_j[2], idx, 0))\n",
    "    filenames_with_labels.append(normal_i[2]+'-'+normal_j[2]+'_'+str(idx)+'_0')\n",
    "    \n",
    "# augment abnormal\n",
    "aug_nos = scale*len(classwise_cycle_list[0]) - len(classwise_cycle_list[1])\n",
    "for idx in range(aug_nos):\n",
    "    aug_prob = random.random()\n",
    "    if aug_prob < 0.6:\n",
    "        # crackle_i + crackle_j\n",
    "        i = random.randint(0, len(classwise_cycle_list[1])-1)\n",
    "        j = random.randint(0, len(classwise_cycle_list[1])-1)\n",
    "        sample_i = classwise_cycle_list[1][i]\n",
    "        sample_j = classwise_cycle_list[1][j]\n",
    "    elif aug_prob >= 0.6 and aug_prob < 0.8:\n",
    "        # crackle_i + normal_j\n",
    "        i = random.randint(0, len(classwise_cycle_list[1])-1)\n",
    "        j = random.randint(0, len(classwise_cycle_list[0])-1)\n",
    "        sample_i = classwise_cycle_list[1][i]\n",
    "        sample_j = classwise_cycle_list[0][j]\n",
    "    else:\n",
    "        # normal_i + crackle_j\n",
    "        i = random.randint(0, len(classwise_cycle_list[0])-1)\n",
    "        j = random.randint(0, len(classwise_cycle_list[1])-1)\n",
    "        sample_i = classwise_cycle_list[0][i]\n",
    "        sample_j = classwise_cycle_list[1][j]\n",
    "\n",
    "    new_sample = np.concatenate([sample_i[0], sample_j[0]])\n",
    "    cycle_list.append((new_sample, 1, sample_i[2]+'-'+sample_j[2], idx, 0))\n",
    "    filenames_with_labels.append(sample_i[2]+'-'+sample_j[2]+'_'+str(idx)+'_1')\n",
    "print(len(cycle_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ede76-2255-4ce9-b91b-6f20d5ff4b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_data = [] # each sample is a tuple with id_0: audio_data, id_1: label, id_2: file_name, id_3: cycle id, id_4: aug id, id_5: split id\n",
    "labels = []\n",
    "desiredLength = 8\n",
    "print('desiredLength*sample_rate: ', desiredLength*sample_rate)\n",
    "output = []\n",
    "for idx, sample in enumerate(cycle_list):\n",
    "    # print(f'{idx}: {sample}')\n",
    "    output_buffer_length = int(desiredLength*sample_rate)\n",
    "    soundclip = sample[0].copy()\n",
    "    # print('soundclip: ', soundclip)\n",
    "    # d = soundclip[0:3]\n",
    "    # b = np.concatenate((soundclip,d))\n",
    "    # print('soundclip copy: ', b)\n",
    "    n_samples = len(soundclip)\n",
    "    # print('n_samples: ', n_samples)\n",
    "    if n_samples < output_buffer_length:\n",
    "        t = output_buffer_length // n_samples\n",
    "        # print('tttt', t)\n",
    "        if output_buffer_length % n_samples == 0:\n",
    "            repeat_sample = np.tile(soundclip, t)\n",
    "            copy_repeat_sample = repeat_sample.copy()\n",
    "            output.append((copy_repeat_sample, sample[4]))\n",
    "        else:\n",
    "            d = output_buffer_length % n_samples\n",
    "            # print('ddddd', d)\n",
    "            d = soundclip[:d]\n",
    "            # print('dddddddd: ', d)\n",
    "            # print('soundclip*t:', len(np.tile(soundclip, t)), n_samples*t)\n",
    "            repeat_sample = np.concatenate((np.tile(soundclip, t), d))\n",
    "            copy_repeat_sample = repeat_sample.copy()\n",
    "            # print('copy_repeat_sample:', len(copy_repeat_sample))\n",
    "            output.append((copy_repeat_sample, sample[4]))\n",
    "    else:\n",
    "        copy_repeat_sample = soundclip[:output_buffer_length]\n",
    "        output.append((copy_repeat_sample, sample[4]))\n",
    "print('----Len Output-----', len(output))        \n",
    "print('----Output-----', output[1][1])\n",
    "audio_data.extend(output)\n",
    "print('len audio data: ', len(audio_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d83f3d-3f20-443d-b77d-e12506a79eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cmapy\n",
    "def create_mel_raw(current_window, sample_rate, n_mels=128, f_min=50, f_max=4000, nfft=2048, hop=512, resz=1):\n",
    "\tS = librosa.feature.melspectrogram(y=current_window, sr=sample_rate, n_mels=n_mels, fmin=f_min, fmax=f_max, n_fft=nfft, hop_length=hop)\n",
    "\tS = librosa.power_to_db(S, ref=np.max)\n",
    "\tS = (S-S.min()) / (S.max() - S.min())\n",
    "\tS *= 255\n",
    "\timg = cv2.applyColorMap(S.astype(np.uint8), cmapy.cmap('magma'))\n",
    "\theight, width, _ = img.shape\n",
    "\tif resz > 0:\n",
    "\t\timg = cv2.resize(img, (width*resz, height*resz), interpolation=cv2.INTER_LINEAR)\n",
    "\timg = cv2.flip(img, 0)\n",
    "\treturn img\n",
    "\n",
    "mel_img = []\n",
    "for index in range(len(audio_data)): #len(audio_data)\n",
    "    audio = audio_data[index][0]\n",
    "    # label\n",
    "    label = audio_data[index][1]    \n",
    "    audio_image = cv2.cvtColor(create_mel_raw(audio, sample_rate, f_max= f_max, \n",
    "            n_mels=n_mels, nfft=nfft, hop=hop, resz=3), cv2.COLOR_BGR2RGB)\n",
    "    mel_img_lable = (audio_image, label)\n",
    "    mel_img.append(mel_img_lable)\n",
    "# for i in range(len(mel_img)):\n",
    "#     print('mel_img: ', mel_img[i][1])\n",
    "for i in range(len(mel_img)):\n",
    "    input_data = mel_img[i][0]\n",
    "    # print(input_data)\n",
    "    lables = mel_img[i][1]\n",
    "    # print(type(lables))\n",
    "    # Create the two folders for the labels\n",
    "    os.makedirs('./data_4gr/normal', exist_ok=True)\n",
    "    os.makedirs('./data_4gr/crackle', exist_ok=True)\n",
    "    os.makedirs('./data_4gr/wheeze', exist_ok=True)\n",
    "    os.makedirs('./data_4gr/both', exist_ok=True)\n",
    "    if lables == 0: #1: abnormal, 0: normal\n",
    "        cv2.imwrite(os.path.join('./data_4gr/normal', 'image_'+str(i)+'.jpg'), cv2.cvtColor(input_data, cv2.COLOR_RGB2BGR))\n",
    "    elif lables == 1:\n",
    "        cv2.imwrite(os.path.join('./data_4gr/crackle', 'image_'+str(i)+'.jpg'), cv2.cvtColor(input_data, cv2.COLOR_RGB2BGR))\n",
    "    elif lables == 2:\n",
    "        cv2.imwrite(os.path.join('./data_4gr/wheeze', 'image_'+str(i)+'.jpg'), cv2.cvtColor(input_data, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        cv2.imwrite(os.path.join('./data_4gr/both', 'image_'+str(i)+'.jpg'), cv2.cvtColor(input_data, cv2.COLOR_RGB2BGR))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3f13e-576d-43f6-b8c8-7c755c0de1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
